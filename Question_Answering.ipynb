{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I read in the data and check the format that it's stored in. I want to make sure to transform the data into the format that simpletransformers takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'qas': [{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Frédéric_Chopin', 'paragraphs': [{'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Sino-Tibetan_relations_during_the_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'IPod', 'paragraphs': [{'qas': [{'qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'The_Legend_of_Zelda:_Twilight_Princ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Infection', 'paragraphs': [{'qas': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Hunting', 'paragraphs': [{'qas': [{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Kathmandu', 'paragraphs': [{'qas': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Myocardial_infarction', 'paragraphs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Matter', 'paragraphs': [{'qas': [{'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    version                                               data\n",
       "0      v2.0  {'title': 'Beyoncé', 'paragraphs': [{'qas': [{...\n",
       "1      v2.0  {'title': 'Frédéric_Chopin', 'paragraphs': [{'...\n",
       "2      v2.0  {'title': 'Sino-Tibetan_relations_during_the_M...\n",
       "3      v2.0  {'title': 'IPod', 'paragraphs': [{'qas': [{'qu...\n",
       "4      v2.0  {'title': 'The_Legend_of_Zelda:_Twilight_Princ...\n",
       "..      ...                                                ...\n",
       "437    v2.0  {'title': 'Infection', 'paragraphs': [{'qas': ...\n",
       "438    v2.0  {'title': 'Hunting', 'paragraphs': [{'qas': [{...\n",
       "439    v2.0  {'title': 'Kathmandu', 'paragraphs': [{'qas': ...\n",
       "440    v2.0  {'title': 'Myocardial_infarction', 'paragraphs...\n",
       "441    v2.0  {'title': 'Matter', 'paragraphs': [{'qas': [{'...\n",
       "\n",
       "[442 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_json(\"./qna/train.json\")\n",
    "eval_data = pd.read_json(\"./qna/test.json\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_data = []\n",
    "for row in train_data.index:\n",
    "    t_data.extend(train_data.iloc[row, 1][\"paragraphs\"])\n",
    "\n",
    "e_data = []\n",
    "for row in eval_data.index:\n",
    "    e_data.extend(eval_data.iloc[row, 1][\"paragraphs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out because github doesnt collapse the cells\n",
    "# t_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the RoBERTa model to train on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "convert squad examples to features: 100%|██████████| 130319/130319 [00:32<00:00, 4050.13it/s] \n",
      "add example index and unique id: 100%|██████████| 130319/130319 [00:00<00:00, 680355.37it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f36475b6a24c68a44a0d8a59e593fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0774b1fc7337460ba2084b215ce64a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/8215 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/de30373/anaconda3/envs/nlp/lib/python3.8/site-packages/simpletransformers/question_answering/question_answering_model.py:751: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "/storage/de30373/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "\n",
      "\n",
      "convert squad examples to features:   0%|          | 0/11873 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:   0%|          | 1/11873 [00:03<11:05:25,  3.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:  13%|█▎        | 1501/11873 [00:03<00:17, 581.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:  17%|█▋        | 2001/11873 [00:03<00:12, 782.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features: 100%|██████████| 11873/11873 [00:06<00:00, 1897.00it/s]A\u001b[A\n",
      "\n",
      "\n",
      "add example index and unique id: 100%|██████████| 11873/11873 [00:00<00:00, 146302.33it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a338cef149f4ef6b4b1e93ba5e86e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "\n",
      "\n",
      "convert squad examples to features:   0%|          | 0/11873 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:   0%|          | 1/11873 [00:03<10:32:21,  3.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:   8%|▊         | 1001/11873 [00:04<00:33, 324.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:  13%|█▎        | 1501/11873 [00:04<00:21, 475.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features: 100%|██████████| 11873/11873 [00:07<00:00, 1635.74it/s]A\u001b[A\n",
      "\n",
      "\n",
      "add example index and unique id: 100%|██████████| 11873/11873 [00:00<00:00, 213764.35it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714a4ed5aa0e4a218985dd0b78f00a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "\n",
      "\n",
      "convert squad examples to features:   0%|          | 0/11873 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:   0%|          | 1/11873 [00:04<16:01:21,  4.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:   8%|▊         | 1001/11873 [00:05<00:40, 266.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:  13%|█▎        | 1501/11873 [00:06<00:29, 348.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:  14%|█▎        | 1620/11873 [00:06<00:27, 378.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:  21%|██        | 2501/11873 [00:07<00:17, 538.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features: 100%|██████████| 11873/11873 [00:08<00:00, 1359.56it/s]A\u001b[A\n",
      "\n",
      "\n",
      "add example index and unique id: 100%|██████████| 11873/11873 [00:00<00:00, 293539.47it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a827245fa647a9b55a7545e5c8693e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "\n",
      "\n",
      "convert squad examples to features:   0%|          | 0/11873 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:   0%|          | 1/11873 [00:03<9:58:16,  3.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:   8%|▊         | 1001/11873 [00:03<00:26, 412.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features:  13%|█▎        | 1501/11873 [00:03<00:17, 594.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "convert squad examples to features: 100%|██████████| 11873/11873 [00:06<00:00, 1883.23it/s]A\u001b[A\n",
      "\n",
      "\n",
      "add example index and unique id: 100%|██████████| 11873/11873 [00:00<00:00, 620756.78it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b921bf8439d64a3c943a8094b4dc7876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "\n",
      "convert squad examples to features:   0%|          | 0/11873 [00:00<?, ?it/s]\u001b[A\n",
      "convert squad examples to features:   0%|          | 1/11873 [00:03<10:39:49,  3.23s/it]\u001b[A\n",
      "convert squad examples to features:   8%|▊         | 1001/11873 [00:03<00:26, 411.01it/s]\u001b[A\n",
      "convert squad examples to features:  13%|█▎        | 1501/11873 [00:03<00:15, 650.69it/s]\u001b[A\n",
      "convert squad examples to features:  17%|█▋        | 2001/11873 [00:03<00:11, 876.82it/s]\u001b[A\n",
      "convert squad examples to features:  21%|██        | 2501/11873 [00:03<00:07, 1219.89it/s]\u001b[A\n",
      "convert squad examples to features: 100%|██████████| 11873/11873 [00:06<00:00, 1745.36it/s][A\n",
      "\n",
      "add example index and unique id: 100%|██████████| 11873/11873 [00:00<00:00, 149488.55it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b64fe84157458b83d4c5c12133e5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "convert squad examples to features: 100%|██████████| 11873/11873 [00:07<00:00, 1531.07it/s]\n",
      "add example index and unique id: 100%|██████████| 11873/11873 [00:00<00:00, 271206.68it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9ebf542d344296ab810d0dcc66b4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 70.36it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 17119.61it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6453c2b07c4d41c78b65d2d008515dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '0', 'answer': ['great power and skill.', 'power and skill.', 'a Mistborn of great power and skill.', 'Mistborn of great power and skill.', 'great power', 'Vin is a Mistborn of great power and skill.', 'power', '', 'skill.', 'a Mistborn of great power', 'Mistborn of great power', 'a Mistborn', 'Mistborn', '.', 'Vin is a Mistborn of great power', 'of great power and skill.', 'Vin is a Mistborn', 'is a Mistborn of great power and skill.', 'and skill.']}]\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Configure the model\n",
    "model_args = QuestionAnsweringArgs()\n",
    "model_args.train_batch_size = 16\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.overwrite_output_dir = True\n",
    "\n",
    "model = QuestionAnsweringModel(\n",
    "    \"roberta\", \"roberta-base\", args=model_args, cuda_device=6\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(t_data, eval_data=e_data)\n",
    "\n",
    "# Evaluate the model\n",
    "result, texts = model.eval_model(e_data)\n",
    "\n",
    "# Make predictions with the model\n",
    "to_predict = [\n",
    "    {\n",
    "        \"context\": \"Vin is a Mistborn of great power and skill.\",\n",
    "        \"qas\": [\n",
    "            {\n",
    "                \"question\": \"What is Vin's speciality?\",\n",
    "                \"id\": \"0\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "answers, probabilities = model.predict(to_predict)\n",
    "\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to ask it a question that was a bot more tricky, one that required more contextual/grammatical understanding. I was throroughly impressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 23.04it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7182.03it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0815e75fb6ae4e9dbdcd05b4b1c01484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([{'id': '0',\n",
       "   'answer': ['Petrela,',\n",
       "    'Dyrrachium using the most sophisticated military equipment of the time, but to no avail. Meanwhile, they occupied Petrela,',\n",
       "    'Petrela, the citadel of Mili at the banks of the river Deabolis, Gllavenica (Ballsh), Kanina and Jericho.',\n",
       "    'Valona and besieged Dyrrachium using the most sophisticated military equipment of the time, but to no avail. Meanwhile, they occupied Petrela,',\n",
       "    'Petrela, the citadel of Mili at the banks of the river Deabolis, Gllavenica (Ballsh), Kanina',\n",
       "    'Petrela, the citadel of Mili',\n",
       "    'Dyrrachium',\n",
       "    'Dyrrachium using the most sophisticated military equipment of the time, but to no avail. Meanwhile, they occupied Petrela, the citadel of Mili at the banks of the river Deabolis, Gllavenica (Ballsh), Kanina and Jericho.',\n",
       "    'Valona and besieged Dyrrachium',\n",
       "    'Valona and besieged Dyrrachium using the most sophisticated military equipment of the time, but to no avail. Meanwhile, they occupied Petrela, the citadel of Mili at the banks of the river Deabolis, Gllavenica (Ballsh), Kanina and Jericho.',\n",
       "    'Valona',\n",
       "    'Petrela, the citadel of Mili at the banks of the river Deabolis,',\n",
       "    '',\n",
       "    'Dyrrachium using the most sophisticated military equipment of the time, but to no avail. Meanwhile, they occupied Petrela, the citadel of Mili at the banks of the river Deabolis, Gllavenica (Ballsh), Kanina',\n",
       "    'Petrela, the citadel of Mili at the banks of the river Deabolis, Gllavenica',\n",
       "    'Dyrrachium using the most sophisticated military equipment of the time, but to no avail. Meanwhile, they occupied Petrela, the citadel of Mili',\n",
       "    'they occupied Petrela,',\n",
       "    'Valona and besieged Dyrrachium using the most sophisticated military equipment of the time, but to no avail. Meanwhile, they occupied Petrela, the citadel of Mili at the banks of the river Deabolis, Gllavenica (Ballsh), Kanina',\n",
       "    'Jericho.']}],\n",
       " [{'id': '0',\n",
       "   'probability': [0.48746307952390383,\n",
       "    0.1221714627921943,\n",
       "    0.08799680357084894,\n",
       "    0.08570689721267173,\n",
       "    0.03233272216796651,\n",
       "    0.0274739419710434,\n",
       "    0.025935710510899518,\n",
       "    0.02205438455726331,\n",
       "    0.018194668575559503,\n",
       "    0.015471803538549997,\n",
       "    0.011452842938579292,\n",
       "    0.010917712040460147,\n",
       "    0.008273376248479056,\n",
       "    0.008103456711372073,\n",
       "    0.007592076808290747,\n",
       "    0.006885714673095852,\n",
       "    0.005999964879294299,\n",
       "    0.005684814731327544,\n",
       "    0.005415390925045902]}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict = [\n",
    "    {\n",
    "        \"context\": \"A few years after the First Crusade, in 1107, the Normans under the command of Bohemond, Robert's son, landed in Valona and besieged Dyrrachium using the most sophisticated military equipment of the time, but to no avail. Meanwhile, they occupied Petrela, the citadel of Mili at the banks of the river Deabolis, Gllavenica (Ballsh), Kanina and Jericho. This time, the Albanians sided with the Normans, dissatisfied by the heavy taxes the Byzantines had imposed upon them. With their help, the Normans secured the Arbanon passes and opened their way to Dibra. The lack of supplies, disease and Byzantine resistance forced Bohemond to retreat from his campaign and sign a peace treaty with the Byzantines in the city of Deabolis.\",\n",
    "        \"qas\": [\n",
    "            {\n",
    "                \"question\": 'What city did the Normans occupy?',\n",
    "                \"id\": \"0\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "model.predict(to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose a random paragraph from the evaluation dataset to make my question from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qas': [{'question': 'Where did the Normans and Byzantines sign the peace treaty?',\n",
       "   'id': '56de15104396321400ee25b7',\n",
       "   'answers': [{'text': 'Deabolis', 'answer_start': 302},\n",
       "    {'text': 'Deabolis', 'answer_start': 718},\n",
       "    {'text': 'Deabolis', 'answer_start': 718}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"Who was Robert's son?\",\n",
       "   'id': '56de15104396321400ee25b8',\n",
       "   'answers': [{'text': 'Bohemond', 'answer_start': 79},\n",
       "    {'text': 'Bohemond', 'answer_start': 79},\n",
       "    {'text': 'Bohemond', 'answer_start': 79}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What river was Petrela located by?',\n",
       "   'id': '56de15104396321400ee25b9',\n",
       "   'answers': [{'text': 'Deabolis', 'answer_start': 302},\n",
       "    {'text': 'the river Deabolis', 'answer_start': 292},\n",
       "    {'text': 'Deabolis', 'answer_start': 302}],\n",
       "   'is_impossible': False},\n",
       "  {'plausible_answers': [{'text': 'Dyrrachium', 'answer_start': 133}],\n",
       "   'question': 'Who did the Normans besiege in the 11th century?',\n",
       "   'id': '5ad3ee2d604f3c001a3ff7e1',\n",
       "   'answers': [],\n",
       "   'is_impossible': True},\n",
       "  {'plausible_answers': [{'text': 'Normans', 'answer_start': 50}],\n",
       "   'question': 'Who did Robert lead agains Dyrrachium in 1107?',\n",
       "   'id': '5ad3ee2d604f3c001a3ff7e2',\n",
       "   'answers': [],\n",
       "   'is_impossible': True},\n",
       "  {'plausible_answers': [{'text': 'Robert', 'answer_start': 89}],\n",
       "   'question': \"Who was Bohemond's son?\",\n",
       "   'id': '5ad3ee2d604f3c001a3ff7e3',\n",
       "   'answers': [],\n",
       "   'is_impossible': True}],\n",
       " 'context': \"A few years after the First Crusade, in 1107, the Normans under the command of Bohemond, Robert's son, landed in Valona and besieged Dyrrachium using the most sophisticated military equipment of the time, but to no avail. Meanwhile, they occupied Petrela, the citadel of Mili at the banks of the river Deabolis, Gllavenica (Ballsh), Kanina and Jericho. This time, the Albanians sided with the Normans, dissatisfied by the heavy taxes the Byzantines had imposed upon them. With their help, the Normans secured the Arbanon passes and opened their way to Dibra. The lack of supplies, disease and Byzantine resistance forced Bohemond to retreat from his campaign and sign a peace treaty with the Byzantines in the city of Deabolis.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
